{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw-_4WUejWR7",
        "outputId": "31f7b7e4-20d9-424d-c5fb-54328c22d2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original array:\n",
            "[87 82 64 71 92 91  5 67 59 97 10 20 27 70 85 22 55 87 62 46]\n",
            "\n",
            "Parallel Sum: 1199\n",
            "Parallel Min: 5\n",
            "Parallel Max: 97\n",
            "Parallel Average: 59.95\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Function for parallel reduction\n",
        "def parallel_reduce(arr, operation, num_threads=4):\n",
        "    chunk_size = len(arr) // num_threads\n",
        "    results = []\n",
        "\n",
        "    def process_chunk(chunk):\n",
        "        if operation == 'sum':\n",
        "            return np.sum(chunk)\n",
        "        elif operation == 'min':\n",
        "            return np.min(chunk)\n",
        "        elif operation == 'max':\n",
        "            return np.max(chunk)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported operation!\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        futures = []\n",
        "        for i in range(num_threads):\n",
        "            start = i * chunk_size\n",
        "            # Last chunk takes any extra elements\n",
        "            end = (i + 1) * chunk_size if i != num_threads - 1 else len(arr)\n",
        "            chunk = arr[start:end]\n",
        "            futures.append(executor.submit(process_chunk, chunk))\n",
        "\n",
        "        for future in futures:\n",
        "            results.append(future.result())\n",
        "\n",
        "    # Final reduction of partial results\n",
        "    if operation == 'sum':\n",
        "        return np.sum(results)\n",
        "    elif operation == 'min':\n",
        "        return np.min(results)\n",
        "    elif operation == 'max':\n",
        "        return np.max(results)\n",
        "\n",
        "# Main\n",
        "arr = np.random.randint(1, 100, size=20)\n",
        "print(f\"Original array:\\n{arr}\")\n",
        "\n",
        "# Parallel operations\n",
        "parallel_sum = parallel_reduce(arr, 'sum')\n",
        "parallel_min = parallel_reduce(arr, 'min')\n",
        "parallel_max = parallel_reduce(arr, 'max')\n",
        "parallel_avg = parallel_sum / len(arr)\n",
        "\n",
        "print(f\"\\nParallel Sum: {parallel_sum}\")\n",
        "print(f\"Parallel Min: {parallel_min}\")\n",
        "print(f\"Parallel Max: {parallel_max}\")\n",
        "print(f\"Parallel Average: {parallel_avg:.2f}\")\n"
      ]
    }
  ]
}