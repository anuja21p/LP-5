{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwiefGb-C4d",
        "outputId": "1f3b7fcf-acb4-4a18-ebda-5c0e48c9f356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-zrwcpj00\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-zrwcpj00\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4290 sha256=40d78be52d979d31b28f349bd42ba4a4267d7c4e60cab447851b767a7c617954\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r3iyed5q/wheels/bc/4e/e0/2d86bd15f671dbeb32144013f1159dba09757fde36dc51a963\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "# Set up CUDA\n",
        "#First Change runtime to GPU and run this cell\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6eOwFLYHJAJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2076c795-ad6e-42dd-9736-fcf5ae03167b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m1.3/1.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.2)\n",
            "Downloading pytools-2025.1.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660425 sha256=23249956253b77b3813008da093ca06dd43da9934d86272e7f1763f71e0274ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, pycuda\n",
            "Successfully installed pycuda-2025.1 pytools-2025.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install pycuda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebqsk_UBG-be",
        "outputId": "9fc86939-6a43-405a-bbfe-937ceb600aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: [4 5 7 0]\n",
            "Vector B: [2 9 2 5]\n",
            "Addition result: [ 6 14  9  5]\n"
          ]
        }
      ],
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# Define CUDA kernel for addition\n",
        "kernel_code = \"\"\"\n",
        "__global__ void add(int *A, int *B, int *C, int size)\n",
        "{\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (tid < size)\n",
        "    {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Initialize vectors with random values\n",
        "def initialize(size):\n",
        "    return np.random.randint(0, 10, size).astype(np.int32)\n",
        "\n",
        "# Print vector\n",
        "def print_vector(vec):\n",
        "    print(\" \".join(map(str, vec)))\n",
        "\n",
        "# Vector size\n",
        "N = 4\n",
        "\n",
        "# Initialize vectors A and B\n",
        "A = initialize(N)\n",
        "B = initialize(N)\n",
        "\n",
        "# Print vectors A and B\n",
        "print(\"Vector A:\", A)\n",
        "print(\"Vector B:\", B)\n",
        "\n",
        "# Allocate memory on the device\n",
        "A_gpu = cuda.mem_alloc(A.nbytes)\n",
        "B_gpu = cuda.mem_alloc(B.nbytes)\n",
        "C_gpu = cuda.mem_alloc(A.nbytes)\n",
        "\n",
        "# Copy input vectors to the device\n",
        "cuda.memcpy_htod(A_gpu, A)\n",
        "cuda.memcpy_htod(B_gpu, B)\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(kernel_code)\n",
        "\n",
        "# Get the kernel function\n",
        "add_kernel = mod.get_function(\"add\")\n",
        "\n",
        "# Define number of threads and blocks\n",
        "threads_per_block = 256\n",
        "blocks_per_grid = (N + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "# Launch the CUDA kernel\n",
        "add_kernel(A_gpu, B_gpu, C_gpu, np.int32(N), block=(threads_per_block, 1, 1), grid=(blocks_per_grid, 1))\n",
        "\n",
        "# Copy the result from device to host\n",
        "C = np.empty_like(A)\n",
        "cuda.memcpy_dtoh(C, C_gpu)\n",
        "\n",
        "# Print the result\n",
        "print(\"Addition result:\", C)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}