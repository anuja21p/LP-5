{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwiefGb-C4d",
        "outputId": "1f3b7fcf-acb4-4a18-ebda-5c0e48c9f356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-zrwcpj00\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-zrwcpj00\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4290 sha256=40d78be52d979d31b28f349bd42ba4a4267d7c4e60cab447851b767a7c617954\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r3iyed5q/wheels/bc/4e/e0/2d86bd15f671dbeb32144013f1159dba09757fde36dc51a963\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "# Set up CUDA\n",
        "#First Change runtime to GPU and run this cell\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6eOwFLYHJAJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2076c795-ad6e-42dd-9736-fcf5ae03167b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m1.3/1.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.2)\n",
            "Downloading pytools-2025.1.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660425 sha256=23249956253b77b3813008da093ca06dd43da9934d86272e7f1763f71e0274ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, pycuda\n",
            "Successfully installed pycuda-2025.1 pytools-2025.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install pycuda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebqsk_UBG-be",
        "outputId": "4c45a3c0-b2cf-4b6e-de4d-bcf770f8236e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "1 5 4 5\n",
            "3 0 3 5\n",
            "1 4 4 0\n",
            "4 6 8 0\n",
            "Matrix B:\n",
            "3 3 2 3\n",
            "2 3 6 5\n",
            "5 8 4 2\n",
            "6 2 8 6\n",
            "Matrix multiplication result (C = A * B):\n",
            "63 60 88 66\n",
            "54 43 58 45\n",
            "31 47 42 31\n",
            "64 94 76 58\n"
          ]
        }
      ],
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# Define CUDA kernel for matrix multiplication\n",
        "kernel_code = \"\"\"\n",
        "__global__ void matmul(int *A, int *B, int *C, int N)\n",
        "{\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    if (row < N && col < N)\n",
        "    {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < N; i++)\n",
        "        {\n",
        "            sum += A[row * N + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Initialize matrices with random values\n",
        "def initialize_matrix(N):\n",
        "    return np.random.randint(0, 10, (N, N)).astype(np.int32)\n",
        "\n",
        "# Print matrix\n",
        "def print_matrix(mat):\n",
        "    for row in mat:\n",
        "        print(\" \".join(map(str, row)))\n",
        "\n",
        "# Matrix size (NxN)\n",
        "N = 4\n",
        "\n",
        "# Initialize matrices A and B\n",
        "A = initialize_matrix(N)\n",
        "B = initialize_matrix(N)\n",
        "\n",
        "# Print matrices A and B\n",
        "print(\"Matrix A:\")\n",
        "print_matrix(A)\n",
        "print(\"Matrix B:\")\n",
        "print_matrix(B)\n",
        "\n",
        "# Allocate memory on the device\n",
        "A_gpu = cuda.mem_alloc(A.nbytes)\n",
        "B_gpu = cuda.mem_alloc(B.nbytes)\n",
        "C_gpu = cuda.mem_alloc(A.nbytes)\n",
        "\n",
        "# Copy input matrices to the device\n",
        "cuda.memcpy_htod(A_gpu, A)\n",
        "cuda.memcpy_htod(B_gpu, B)\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(kernel_code)\n",
        "\n",
        "# Get the kernel function\n",
        "matmul_kernel = mod.get_function(\"matmul\")\n",
        "\n",
        "# Define number of threads per block and blocks per grid\n",
        "threads_per_block = (16, 16, 1)  # Block size (16x16 threads per block)\n",
        "blocks_per_grid = (int(np.ceil(N / threads_per_block[0])),\n",
        "                   int(np.ceil(N / threads_per_block[1])))  # Grid size\n",
        "\n",
        "# Launch the CUDA kernel\n",
        "matmul_kernel(A_gpu, B_gpu, C_gpu, np.int32(N), block=threads_per_block, grid=blocks_per_grid)\n",
        "\n",
        "# Copy the result from device to host\n",
        "C = np.empty_like(A)\n",
        "cuda.memcpy_dtoh(C, C_gpu)\n",
        "\n",
        "# Print the result\n",
        "print(\"Matrix multiplication result (C = A * B):\")\n",
        "print_matrix(C)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}